{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"12dKb3_-KqGZCy_q5RBUx8bnW-kX79ede","authorship_tag":"ABX9TyNvO2XCV1ltgZDC20zxIFRE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from pandas import datetime\n","\n","from itertools import product\n","import scipy.stats as scs\n","import warnings\n","\n","import xgboost\n","import lightgbm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcxnFHDtopmP","executionInfo":{"status":"ok","timestamp":1668656021957,"user_tz":-540,"elapsed":441,"user":{"displayName":"어흥범주","userId":"10554293130336392046"}},"outputId":"6bb7bce6-4bce-408e-94f4-e9292efc9f29"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n","  import sys\n"]}]},{"cell_type":"code","source":["pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGHuzfcwq1u4","executionInfo":{"status":"ok","timestamp":1668656373202,"user_tz":-540,"elapsed":9022,"user":{"displayName":"어흥범주","userId":"10554293130336392046"}},"outputId":"13aa34c0-1444-403f-bbf2-8c944664c328"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting optuna\n","  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n","\u001b[K     |████████████████████████████████| 348 kB 4.7 MB/s \n","\u001b[?25hCollecting cmaes>=0.8.2\n","  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n","Collecting cliff\n","  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 9.5 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.43)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n","Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n","Collecting alembic>=1.5.0\n","  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 70.1 MB/s \n","\u001b[?25hCollecting colorlog\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n","Collecting autopage>=0.4.0\n","  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n","Collecting pbr!=2.1.0,>=2.0.0\n","  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 76.5 MB/s \n","\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n","Collecting cmd2>=1.0.0\n","  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 71.8 MB/s \n","\u001b[?25hCollecting stevedore>=2.0.1\n","  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Collecting pyperclip>=1.6\n","  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n","Building wheels for collected packages: pyperclip\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=47f3952821de49ebaa92960088b8c6238baaab9851d996321228e17ac475d400\n","  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n","Successfully built pyperclip\n","Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"]}]},{"cell_type":"code","source":["import optuna\n","from optuna import Trial, visualization\n","from optuna.samplers import TPESampler"],"metadata":{"id":"x5L99h6Nq0Gg","executionInfo":{"status":"ok","timestamp":1668656377471,"user_tz":-540,"elapsed":459,"user":{"displayName":"어흥범주","userId":"10554293130336392046"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/데이터/찐최종 데이터/구글클라우드플랫폼/seoul_final.csv',\n","                    encoding = 'UTF-8')"],"metadata":{"id":"Lq4-c7oBodRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","def get_clf_eval(y_test, pred=None, pred_proba=None):\n","    print('오차행렬 \\n', confusion_matrix(y_test, pred))\n","    print('정확도 :', accuracy_score(y_test, pred))\n","    print('정밀도 : ',precision_score(y_test, pred))\n","    print('재현율 :', recall_score(y_test, pred))\n","    print('f1 score :', f1_score(y_test, pred))\n","    print('roc auc score :', roc_auc_score(y_test, pred_proba))"],"metadata":{"id":"-c0VMK19oTKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/데이터/찐최종 데이터/구글클라우드플랫폼/기상호우태풍병합데이터(찐찐최종).csv',\n","                   encoding = 'UTF-8')"],"metadata":{"id":"6WuGetLWvu_i","executionInfo":{"status":"ok","timestamp":1668657792061,"user_tz":-540,"elapsed":738,"user":{"displayName":"어흥범주","userId":"10554293130336392046"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FC92oy63wUyj","executionInfo":{"status":"ok","timestamp":1668657808516,"user_tz":-540,"elapsed":368,"user":{"displayName":"어흥범주","userId":"10554293130336392046"}},"outputId":"aee0e699-39ae-42ce-dbc3-61e7ea63420f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 67269 entries, 0 to 67268\n","Data columns (total 18 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   Unnamed: 0     67269 non-null  int64  \n"," 1   Unnamed: 0.1   67269 non-null  int64  \n"," 2   date           67269 non-null  object \n"," 3   add            67269 non-null  object \n"," 4   ca             67269 non-null  float64\n"," 5   avg_ws         67269 non-null  float64\n"," 6   mix_ws         67269 non-null  float64\n"," 7   max_ws         67269 non-null  float64\n"," 8   max_ws_wd      67269 non-null  float64\n"," 9   max_wd         67269 non-null  float64\n"," 10  max_ins_ws     67269 non-null  float64\n"," 11  max_ins_ws_wd  67269 non-null  float64\n"," 12  mix_wd         67269 non-null  float64\n"," 13  avg_ta         67269 non-null  float64\n"," 14  sum_rn         67269 non-null  float64\n"," 15  typhoon_yn     67269 non-null  float64\n"," 16  damage_conv    67269 non-null  float64\n"," 17  rain_yn        67269 non-null  float64\n","dtypes: float64(14), int64(2), object(2)\n","memory usage: 9.2+ MB\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TAxYux4zxSc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lANc8YBemw9E"},"outputs":[],"source":["# 모델\n","model = LGBMClassifier(scale_pos_weight=14,\n","                       boosting='gbdt', # gradient boosting decision tree\n","                       learning_rate=0.05,\n","                       boost_from_average=False, # 불균형한 데이터\n","                       num_iterations=3000,\n","                       max_depth=10, #tree 최대깊이 과적합시 줄여야\n","                       max_leaves=1024, #전체 트리 leaf 수\n","                       n_jobs=-1,\n","                       metric='binary_logloss', # 지표 파라미터\n","                       objective='binary',\n","                       application = 'binary')\n","\n","evals = [(X_test, y_test)]\n","\n","# 모델 학습\n","model.fit(X_train, y_train, early_stopping_rounds=100,eval_set=evals, verbose = 5)\n","\n","# 모델 적합\n","y_pred = model.predict(X_test)"]},{"cell_type":"code","source":["def objectiveLGB(trial: Trial, X, y):\n","    param = {\n","        'boosting_type' : 'gbdt',\n","        \"n_estimators\" : 10000,\n","        'max_depth':trial.suggest_int('max_depth', 4, 16),\n","        'random_state': 722,\n","        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n","        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0),\n","        'num_leaves': trial.suggest_int('num_leaves', 8, 32),\n","        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n","        'subsample': trial.suggest_uniform('subsample', 0.8, 1.0),\n","        'subsample_freq': trial.suggest_int('subsample_freq', 1, 8),\n","        'min_child_samples': trial.suggest_int('min_child_samples', 16, 64),\n","        'learning_rate': 0.025\n","    }\n","    score = lgbm_params_fold_start(param, X, y)\n","\n","    return score"],"metadata":{"id":"_ZIZDYSsrG30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from lightgbm import LGBMClassifier\n","\n","LGBM_parameter_bounds ={\n","    'num_leaves':(24, 45),\n","    'min_child_weight':(5, 50),\n","    'bagging_freq':(0.5,2),\n","    'max_depth':(5, 8.99),\n","    'learning_rate':(0.5,0.8),\n","    'n_estimators':(100,800)\n","                 \n","}\n","\n","def lgbm_bo(num_leaves, min_child_weight, bagging_freq, max_depth, learning_rate,n_estimators):\n","    \n","    LGBM_parameter_bounds = {\n","        'num_leaves':int(round(num_leaves)),\n","        'min_child_weight': int(round(min_child_weight)),\n","        'bagging_freq':int(round(bagging_freq)),\n","        'max_depth': int(round(max_depth)),\n","        'learning_rate': int(round(learning_rate)),\n","         'n_estimators': int(round(n_estimators))\n","        \n","    }\n","    lgbm = LGBMClassifier(** LGBM_parameter_bounds,n_jobs=-1,is_unbalanced = True, random_state=804, \n","                         , boosting_type = 'gbdt')\n","    \n","    x_train, x_val, y_train_split, y_val_split = train_test_split(X_train, y_train,\n","                                                                  test_size=0.2, random_state=804)\n","    \n","    lgbm.fit(x_train, y_train_split)\n","    \n","    f1 = f1_score(y_val_split, lgbm.predict(x_val),average='macro')\n","    return f1\n","\n","optimizer = BayesianOptimization(f=lgbm_bo,\n","                                pbounds=LGBM_parameter_bounds,\n","                                random_state=804) \n","\n","optimizer.maximize(init_points = 5, n_iter = 7)'''"],"metadata":{"id":"KOsw72RJn9RK"},"execution_count":null,"outputs":[]}]}